import hashlib
import json
import logging
import re
import time
from dataclasses import dataclass
from datetime import datetime, timezone
from enum import Enum
from typing import Any, Dict, List, Optional

from .enhanced_abstraction import (  # type: ignore)


    AbstractDatabaseClient,
    Advanced,
    Automatic,
    Benefits:,
    Better,
    Centralized,
    Cross-database,
    DatabaseType,
    Dynamic,
    Enhanced,
    Improved,
    Manager,
    Performance,
    PlexiChat,
    Prepared,
    Procedure,
    Procedures,
    Query,
    QueryType,
    Reduced,
    Statements,
    Stored,
    """,
    -,
    .query_optimizer,
    and,
    based,
    benchmarking,
    business,
    caching,
    calls,
    compatibility,
    compilation,
    complex,
    creation,
    database,
    execution,
    featuring:,
    for,
    from,
    generation,
    import,
    logic,
    management,
    migration,
    monitoring,
    network,
    on,
    optimization,
    parameterized,
    patterns,
    performance,
    performance_monitor,
    plan,
    procedure,
    queries,
    query,
    reuse,
    security,
    sql_analyzer,
    statement,
    stored,
    system,
    through,
    time,
    traffic,
    try:,
    versioning,
)

    ENHANCED_ABSTRACTION_AVAILABLE = True
except ImportError:
    ENHANCED_ABSTRACTION_AVAILABLE = False
    # Create placeholder classes
    class AbstractDatabaseClient:
        def __init__(self, config):
            self.config = config
        async def execute_query(self, query, params=None):
            return {"success": True, "data": []}

    class DatabaseType:
        POSTGRESQL = "postgresql"
        MYSQL = "mysql"
        SQLITE = "sqlite"

    class QueryType:
        SELECT = "select"
        INSERT = "insert"
        UPDATE = "update"
        DELETE = "delete"
logger = logging.getLogger(__name__)


class ProcedureType(Enum):
    """Types of stored procedures."""
    QUERY = "query"  # SELECT procedures
    MUTATION = "mutation"  # INSERT/UPDATE/DELETE procedures
    AGGREGATE = "aggregate"  # Complex aggregation procedures
    BATCH = "batch"  # Batch operation procedures
    MAINTENANCE = "maintenance"  # Database maintenance procedures


class ProcedureStatus(Enum):
    """Stored procedure status."""
    ACTIVE = "active"
    CREATING = "creating"
    DEPRECATED = "deprecated"
    FAILED = "failed"
    OPTIMIZING = "optimizing"


@dataclass
class StoredProcedure:
    """Stored procedure definition."""
    name: str
    procedure_type: ProcedureType
    database_type: DatabaseType
    sql_definition: str
    parameters: List[Dict[str, str]]  # [{"name": "param1", "type": "INTEGER", "default": None}]
    return_type: Optional[str] = None

    # Metadata
    description: str = ""
    created_at: Optional[datetime] = None
    updated_at: Optional[datetime] = None
    version: int = 1

    # Performance metrics
    execution_count: int = 0
    total_execution_time_ms: float = 0.0
    avg_execution_time_ms: float = 0.0
    last_executed: Optional[datetime] = None

    # Status
    status: ProcedureStatus = ProcedureStatus.ACTIVE

    def to_sql(self) -> str:
        """Generate SQL for procedure creation."""
        if self.database_type == DatabaseType.POSTGRESQL:
            return self._to_postgresql_sql()
        elif self.database_type == DatabaseType.MYSQL:
            return self._to_mysql_sql()
        elif self.database_type == DatabaseType.SQLITE:
            # SQLite doesn't support stored procedures, return function comment
            return f"-- SQLite stored procedure: {self.name}\n-- {self.description}\n{self.sql_definition}"
        else:
            return self._to_generic_sql()

    def _to_postgresql_sql(self) -> str:
        """Generate PostgreSQL stored procedure SQL."""
        params_sql = ", ".join([)
            f"{param['name']} {param['type']}" + (f" DEFAULT {param['default']}" if param.get('default') else "")
            for param in self.parameters
        ])

        return_clause = f"RETURNS {self.return_type}" if self.return_type else "RETURNS VOID"

        return f"""
CREATE OR REPLACE FUNCTION {self.name}({params_sql})
{return_clause}
LANGUAGE plpgsql
AS $$
BEGIN
    {self.sql_definition}
END;
$$;

COMMENT ON FUNCTION {self.name} IS '{self.description}';
"""

    def _to_mysql_sql(self) -> str:
        """Generate MySQL stored procedure SQL."""
        params_sql = ", ".join([)
            f"IN {param['name']} {param['type']}"
            for param in self.parameters
        ])

        return f"""
DELIMITER //
CREATE PROCEDURE {self.name}({params_sql})
COMMENT '{self.description}'
BEGIN
    {self.sql_definition}
END //
DELIMITER ;
"""

    def _to_generic_sql(self) -> str:
        """Generate generic SQL (fallback)."""
        return f"-- Stored procedure: {self.name}\n{self.sql_definition}"


@dataclass
class PreparedStatement:
    """Prepared statement definition."""
    name: str
    sql_template: str
    parameter_types: Dict[str, str]
    database_type: DatabaseType

    # Performance metrics
    execution_count: int = 0
    total_execution_time_ms: float = 0.0
    avg_execution_time_ms: float = 0.0
    cache_hits: int = 0
    cache_misses: int = 0

    # Metadata
    created_at: Optional[datetime] = None
    last_executed: Optional[datetime] = None

    def get_cache_key(self, parameters: Dict[str, Any]) -> str:
        """Generate cache key for prepared statement with parameters."""
        param_str = json.dumps(parameters, sort_keys=True, default=str)
        return hashlib.md5(f"{self.name}:{param_str}".encode()).hexdigest()


class ProcedureGenerator:
    """Generate stored procedures from query patterns."""

    def __init__(self):
        self.common_patterns = {
            "user_lookup": {
                "pattern": r"SELECT .* FROM users WHERE (\w+) = \$(\w+)",
                "template": "get_user_by_{column}",
                "type": ProcedureType.QUERY
            },
            "message_insert": {
                "pattern": r"INSERT INTO messages \(([^)]+)\) VALUES \(([^)]+)\)",
                "template": "insert_message",
                "type": ProcedureType.MUTATION
            },
            "channel_stats": {
                "pattern": r"SELECT COUNT\(\*\).* FROM messages .* GROUP BY channel_id",
                "template": "get_channel_message_stats",
                "type": ProcedureType.AGGREGATE
            },
            "user_activity": {
                "pattern": r"SELECT .* FROM \w+ WHERE user_id = \$\w+ AND created_at >= \$\w+",
                "template": "get_user_activity",
                "type": ProcedureType.QUERY
            }
        }

    def analyze_query_for_procedure(self, query: str, execution_count: int = 1) -> Optional[StoredProcedure]:
        """Analyze if a query should be converted to a stored procedure."""
        # Only consider frequently executed queries
        if execution_count < 10:
            return None

        query_clean = self._clean_query(query)

        # Check against common patterns
        for pattern_name, pattern_info in self.common_patterns.items():
            if re.search(pattern_info["pattern"], query_clean, re.IGNORECASE):
                return self._generate_procedure_from_pattern(query_clean, pattern_name, pattern_info)

        # Check for complex queries that would benefit from procedures
        analysis = sql_analyzer.analyze_query(query)
        if analysis.complexity_score > 5.0:
            return self._generate_complex_query_procedure(query_clean, analysis)

        return None

    def _generate_procedure_from_pattern(self, query: str, pattern_name: str,):
                                       pattern_info: Dict[str, Any]) -> StoredProcedure:
        """Generate stored procedure from a recognized pattern."""
        # Extract parameters from query
        parameters = self._extract_parameters(query)

        # Generate procedure name
        proc_name = f"sp_{pattern_info['template']}"

        # Create procedure definition
        return StoredProcedure()
            name=proc_name,
            procedure_type=pattern_info["type"],
            database_type=DatabaseType.POSTGRESQL,  # Default, will be adjusted
            sql_definition=self._convert_query_to_procedure_body(query),
            parameters=parameters,
            description=f"Auto-generated procedure for {pattern_name} pattern",
            created_at=datetime.now(timezone.utc)
        )

    def _generate_complex_query_procedure(self, query: str, analysis) -> StoredProcedure:
        """Generate procedure for complex queries."""
        parameters = self._extract_parameters(query)

        # Generate name based on tables accessed
        table_names = "_".join(analysis.tables_accessed[:2])  # Limit to 2 tables
        proc_name = f"sp_complex_{table_names}"

        return StoredProcedure()
            name=proc_name,
            procedure_type=ProcedureType.QUERY,
            database_type=DatabaseType.POSTGRESQL,
            sql_definition=self._convert_query_to_procedure_body(query),
            parameters=parameters,
            description=f"Complex query procedure for tables: {', '.join(analysis.tables_accessed)}",
            created_at=datetime.now(timezone.utc)
        )

    def _clean_query(self, query: str) -> str:
        """Clean and normalize query."""
        return re.sub(r'\s+', ' ', query.strip())

    def _extract_parameters(self, query: str) -> List[Dict[str, str]]:
        """Extract parameters from parameterized query."""
        parameters = []

        # Find parameter placeholders ($1, $param_name, etc.)
        param_patterns = [
            r'\$(\w+)',  # $param_name
            r'\$(\d+)',  # $1, $2, etc.
            r':(\w+)',   # :param_name
            r'\?'        # ? placeholder
        ]

        param_names = set()
        for pattern in param_patterns:
            matches = re.findall(pattern, query)
            param_names.update(matches)

        # Generate parameter definitions (with default types)
        for param_name in param_names:
            if param_name.isdigit():
                param_name = f"param_{param_name}"

            parameters.append({)
                "name": param_name,
                "type": "TEXT",  # Default type, should be refined
                "default": None
            })

        return parameters

    def _convert_query_to_procedure_body(self, query: str) -> str:
        """Convert SQL query to procedure body."""
        # For SELECT queries, add RETURN QUERY
        if query.strip().upper().startswith('SELECT'):
            return f"RETURN QUERY {query};"
        else:
            return f"{query};"


class PreparedStatementManager:
    """Manage prepared statements and query caching."""

    def __init__(self):
        self.prepared_statements: Dict[str, PreparedStatement] = {}
        self.query_cache: Dict[str, Any] = {}
        self.cache_max_size = 1000
        self.cache_ttl_seconds = 3600

    def prepare_statement(self, name: str, sql_template: str,):
                         parameter_types: Dict[str, str],
                         database_type: DatabaseType) -> PreparedStatement:
        """Prepare a SQL statement for reuse."""
        stmt = PreparedStatement()
            name=name,
            sql_template=sql_template,
            parameter_types=parameter_types,
            database_type=database_type,
            created_at=datetime.now(timezone.utc)
        )

        self.prepared_statements[name] = stmt
        logger.info(f" Prepared statement: {name}")

        return stmt

    async def execute_prepared(self, client: AbstractDatabaseClient,)
                             statement_name: str, parameters: Dict[str, Any]) -> Any:
        """Execute a prepared statement with caching."""
        if statement_name not in self.prepared_statements:
            raise ValueError(f"Prepared statement '{statement_name}' not found")

        stmt = self.prepared_statements[statement_name]
        cache_key = stmt.get_cache_key(parameters)

        # Check cache first
        cached_result = self._get_from_cache(cache_key)
        if cached_result:
            stmt.cache_hits += 1
            return cached_result

        # Execute statement
        start_time = time.time()

        # Substitute parameters in SQL template
        sql = self._substitute_parameters(stmt.sql_template, parameters)

        try:
            result = await client.execute_query(sql, parameters)

            execution_time_ms = (time.time() - start_time) * 1000

            # Update statistics
            stmt.execution_count += 1
            stmt.total_execution_time_ms += execution_time_ms
            stmt.avg_execution_time_ms = stmt.total_execution_time_ms / stmt.execution_count
            stmt.last_executed = datetime.now(timezone.utc)
            stmt.cache_misses += 1

            # Cache result for SELECT queries
            if sql.strip().upper().startswith('SELECT'):
                self._add_to_cache(cache_key, result)

            return result

        except Exception as e:
            logger.error(f"Failed to execute prepared statement {statement_name}: {e}")
            raise

    def _substitute_parameters(self, sql_template: str, parameters: Dict[str, Any]) -> str:
        """Substitute parameters in SQL template."""
        sql = sql_template

        for param_name, param_value in parameters.items():
            # Handle different parameter formats
            placeholders = [
                f"${param_name}",
                f":{param_name}",
                f"{{{param_name}}}"
            ]

            for placeholder in placeholders:
                if isinstance(param_value, str):
                    sql = sql.replace(placeholder, f"'{param_value}'")
                else:
                    sql = sql.replace(placeholder, str(param_value))

        return sql

    def _get_from_cache(self, cache_key: str) -> Optional[Any]:
        """Get result from cache."""
        if cache_key in self.query_cache:
            cached_item = self.query_cache[cache_key]

            # Check if cache item is still valid
            if (datetime.now(timezone.utc) - cached_item["timestamp"]).total_seconds() < self.cache_ttl_seconds:
                return cached_item["result"]
            else:
                # Remove expired item
                del self.query_cache[cache_key]

        return None

    def _add_to_cache(self, cache_key: str, result: Any):
        """Add result to cache."""
        # Implement LRU eviction if cache is full
        if len(self.query_cache) >= self.cache_max_size:
            # Remove oldest item
            oldest_key = min(self.query_cache.keys(),)
                           key=lambda k: self.query_cache[k]["timestamp"])
            del self.query_cache[oldest_key]

        self.query_cache[cache_key] = {
            "result": result,
            "timestamp": datetime.now(timezone.utc)
        }

    def get_cache_stats(self) -> Dict[str, Any]:
        """Get cache performance statistics."""
        total_hits = sum(stmt.cache_hits for stmt in self.prepared_statements.values())
        total_misses = sum(stmt.cache_misses for stmt in self.prepared_statements.values())
        total_requests = total_hits + total_misses

        hit_rate = (total_hits / total_requests * 100) if total_requests > 0 else 0

        return {
            "cache_size": len(self.query_cache),
            "max_cache_size": self.cache_max_size,
            "total_hits": total_hits,
            "total_misses": total_misses,
            "hit_rate_percentage": hit_rate,
            "prepared_statements_count": len(self.prepared_statements)
        }


class StoredProcedureManager:
    """Manage stored procedures across databases."""

    def __init__(self):
        self.procedures: Dict[str, Dict[str, StoredProcedure]] = {}  # db_name -> proc_name -> procedure
        self.generator = ProcedureGenerator()
        self.prepared_manager = PreparedStatementManager()

    async def analyze_and_create_procedures(self, database_name: str,)
                                          client: AbstractDatabaseClient) -> List[str]:
        """Analyze query patterns and create stored procedures."""
        created_procedures = []
        database_type = getattr(client.config, 'type', DatabaseType.SQLITE)

        # Skip for SQLite (no stored procedure support)
        if database_type == DatabaseType.SQLITE:
            logger.info("SQLite doesn't support stored procedures, using prepared statements instead")
            return created_procedures

        try:
            # Analyze query patterns from performance monitor
            query_stats = performance_monitor.query_stats

            for query_hash, stats in query_stats.items():
                count = stats.get("count", 0)
                if count is not None and count >= 10:  # Frequently executed queries
                    # We'd need the actual query text here
                    # For demonstration, we'll create some common procedures
                    procedures = self._create_common_procedures(database_type)

                    for procedure in procedures:
                        success = await self._create_procedure(client, procedure)
                        if success:
                            if database_name not in self.procedures:
                                self.procedures[database_name] = {}
                            self.procedures[database_name][procedure.name] = procedure
                            created_procedures.append(procedure.name)

        except Exception as e:
            logger.error(f"Failed to analyze and create procedures for {database_name}: {e}")

        return created_procedures

    def _create_common_procedures(self, database_type: DatabaseType) -> List[StoredProcedure]:
        """Create common stored procedures for PlexiChat."""
        procedures = []

        # User lookup procedure
        user_lookup = StoredProcedure()
            name="sp_get_user_by_id",
            procedure_type=ProcedureType.QUERY,
            database_type=database_type,
            sql_definition="SELECT * FROM users WHERE id = user_id_param;",
            parameters=[{"name": "user_id_param", "type": "INTEGER", "default": ""}],
            return_type="TABLE(id INTEGER, username TEXT, email TEXT, created_at TIMESTAMP)",
            description="Get user by ID with optimized query plan"
        )
        procedures.append(user_lookup)

        # Message insertion procedure
        message_insert = StoredProcedure()
            name="sp_insert_message",
            procedure_type=ProcedureType.MUTATION,
            database_type=database_type,
            sql_definition="""
                INSERT INTO messages (channel_id, user_id, content, created_at)
                VALUES (channel_id_param, user_id_param, content_param, NOW())
                RETURNING id;
            """,
            parameters=[
                {"name": "channel_id_param", "type": "INTEGER", "default": ""},
                {"name": "user_id_param", "type": "INTEGER", "default": ""},
                {"name": "content_param", "type": "TEXT", "default": ""}
            ],
            return_type="INTEGER",
            description="Insert new message and return message ID"
        )
        procedures.append(message_insert)

        # Channel statistics procedure
        channel_stats = StoredProcedure()
            name="sp_get_channel_stats",
            procedure_type=ProcedureType.AGGREGATE,
            database_type=database_type,
            sql_definition="""
                SELECT
                    channel_id,
                    COUNT(*) as message_count,
                    COUNT(DISTINCT user_id) as unique_users,
                    MAX(created_at) as last_message_at
                FROM messages
                WHERE channel_id = channel_id_param
                  AND created_at >= start_date_param
                GROUP BY channel_id;
            """,
            parameters=[
                {"name": "channel_id_param", "type": "INTEGER", "default": ""},
                {"name": "start_date_param", "type": "TIMESTAMP", "default": "NOW() - INTERVAL '30 days'"}
            ],
            return_type="TABLE(channel_id INTEGER, message_count INTEGER, unique_users INTEGER, last_message_at TIMESTAMP)",
            description="Get channel statistics for specified time period"
        )
        procedures.append(channel_stats)

        return procedures

    async def _create_procedure(self, client: AbstractDatabaseClient,)
                              procedure: StoredProcedure) -> bool:
        """Create a stored procedure in the database."""
        try:
            create_sql = procedure.to_sql()
            await client.execute_query(create_sql)

            procedure.status = ProcedureStatus.ACTIVE
            procedure.created_at = datetime.now(timezone.utc)

            logger.info(f" Created stored procedure: {procedure.name}")
            return True

        except Exception as e:
            procedure.status = ProcedureStatus.FAILED
            logger.error(f" Failed to create stored procedure {procedure.name}: {e}")
            return False

    async def execute_procedure(self, client: AbstractDatabaseClient,)
                              database_name: str, procedure_name: str,
                              parameters: Dict[str, Any]) -> Any:
        """Execute a stored procedure."""
        if (database_name not in self.procedures or)
            procedure_name not in self.procedures[database_name]):
            raise ValueError(f"Stored procedure '{procedure_name}' not found in database '{database_name}'")

        procedure = self.procedures[database_name][procedure_name]

        # Build procedure call SQL
        param_list = ", ".join([f"${param['name']}" for param in procedure.parameters])
        call_sql = f"SELECT * FROM {procedure_name}({param_list})"

        start_time = time.time()

        try:
            result = await client.execute_query(call_sql, parameters)

            execution_time_ms = (time.time() - start_time) * 1000

            # Update procedure statistics
            procedure.execution_count += 1
            procedure.total_execution_time_ms += execution_time_ms
            procedure.avg_execution_time_ms = procedure.total_execution_time_ms / procedure.execution_count
            procedure.last_executed = datetime.now(timezone.utc)

            return result

        except Exception as e:
            logger.error(f"Failed to execute procedure {procedure_name}: {e}")
            raise

    def get_procedure_performance_report(self, database_name: str) -> Dict[str, Any]:
        """Generate performance report for stored procedures."""
        if database_name not in self.procedures:
            return {"database": database_name, "procedures": []}

        procedures = self.procedures[database_name]

        procedure_stats = []
        for proc_name, procedure in procedures.items():
            procedure_stats.append({)
                "name": proc_name,
                "type": procedure.procedure_type.value,
                "execution_count": procedure.execution_count,
                "avg_execution_time_ms": procedure.avg_execution_time_ms,
                "total_execution_time_ms": procedure.total_execution_time_ms,
                "last_executed": procedure.last_executed.isoformat() if procedure.last_executed else None,
                "status": procedure.status.value
            })

        # Sort by execution count
        procedure_stats.sort(key=lambda x: x["execution_count"], reverse=True)

        return {
            "database": database_name,
            "total_procedures": len(procedures),
            "active_procedures": len([p for p in procedures.values() if p.status == ProcedureStatus.ACTIVE]),
            "total_executions": sum(p.execution_count for p in procedures.values()),
            "procedures": procedure_stats,
            "cache_stats": self.prepared_manager.get_cache_stats()
        }


# Global instances
procedure_manager = StoredProcedureManager()
prepared_statement_manager = PreparedStatementManager()
